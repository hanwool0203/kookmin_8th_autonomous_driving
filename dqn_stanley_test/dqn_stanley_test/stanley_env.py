# íŒŒì¼ëª…: stanley_env_refactored.py

import rclpy
from rclpy.node import Node
from geometry_msgs.msg import Point
import numpy as np
from std_msgs.msg import Float32MultiArray, Bool
import threading
import sys
import termios
import tty
from collections import deque
import torch
import math

from dqn_stanley_test.dqn_agent import DQNAgent

class StanleyEnv(Node):
    """
    ê°•í™”í•™ìŠµ 'í™˜ê²½(Environment)'ê³¼ ROS2 'ë…¸ë“œ(Node)'ì˜ ì—­í• ì„ ë™ì‹œì— ìˆ˜í–‰í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    ë¡œë´‡(ì‹œë®¬ë ˆì´í„°)ìœ¼ë¡œë¶€í„° ì„¼ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì‹ í•˜ì—¬ 'ìƒíƒœ(State)'ë¥¼ ì •ì˜í•˜ê³ ,
    í•™ìŠµ ì—ì´ì „íŠ¸ê°€ ê²°ì •í•œ 'í–‰ë™(Action)'ì„ í†µí•´ Stanley ì œì–´ íŒŒë¼ë¯¸í„°ë¥¼ ë™ì ìœ¼ë¡œ ê²°ì •í•©ë‹ˆë‹¤.
    """
    def __init__(self, test_mode=False):
        node_name = 'stanley_test_node' if test_mode else 'stanley_env_and_trainer'
        super().__init__(node_name)

        self.is_test_mode = test_mode

        # --- ê°•í™”í•™ìŠµ(RL) í•µì‹¬ ìš”ì†Œ ---
        self.state_dim = 6
        self.action_dim = 7  # 6ê°œì˜ íŒŒë¼ë¯¸í„° ì¡°ì • + 1ê°œì˜ ì•„ë¬´ê²ƒë„ ì•ˆ í•¨(no-op)
        self.agent = DQNAgent(state_dim=self.state_dim, action_dim=self.action_dim)
        
        ### ë³€ê²½ì  1: ì œì–´ íŒŒë¼ë¯¸í„° ì¤‘ì•™ ê´€ë¦¬ ###
        # Stanley ì œì–´ì— ì‚¬ìš©ë  íŒŒë¼ë¯¸í„°ë“¤ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë¬¶ì–´ ê´€ë¦¬í•©ë‹ˆë‹¤.
        # ì´ íŒŒë¼ë¯¸í„°ë“¤ì´ RL ì—ì´ì „íŠ¸ì˜ 'í•™ìŠµ ëŒ€ìƒ'ì´ ë©ë‹ˆë‹¤.
        self.control_params = {
            'k': 1.2,           # CTEì— ëŒ€í•œ ê²Œì¸
            'speed': 15.0,      # ëª©í‘œ ì†ë„
            'heading_weight': 0.4 # ì „ë°© ì£¼ì‹œê° ì˜¤ì°¨ì— ëŒ€í•œ ê°€ì¤‘ì¹˜
        }
        
        ### ë³€ê²½ì  2: ëª…ì‹œì ì¸ í–‰ë™(Action) ì •ì˜ ###
        # action ì •ìˆ˜ ê°’ì— ë”°ë¼ ì–´ë–¤ íŒŒë¼ë¯¸í„°ë¥¼ ì–´ë–»ê²Œ ë³€ê²½í• ì§€ ëª…ì‹œì ìœ¼ë¡œ ë§¤í•‘í•©ë‹ˆë‹¤.
        # lambda í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì½”ë“œì˜ ê°€ë…ì„±ê³¼ í™•ì¥ì„±ì„ ë†’ì…ë‹ˆë‹¤.
        self.action_map = [
            lambda p: self._update_param(p, 'k', -0.1),      # action 0: k ê°ì†Œ
            lambda p: self._update_param(p, 'k', 0.1),       # action 1: k ì¦ê°€
            lambda p: self._update_param(p, 'heading_weight', -0.05), # action 2: heading_weight ê°ì†Œ
            lambda p: self._update_param(p, 'heading_weight', 0.05),  # action 3: heading_weight ì¦ê°€
            lambda p: self._update_param(p, 'speed', -2.0),     # action 4: speed ê°ì†Œ
            lambda p: self._update_param(p, 'speed', 1.0),      # action 5: speed ì¦ê°€
            lambda p: p # action 6: No-op (ì•„ë¬´ê²ƒë„ ë³€ê²½í•˜ì§€ ì•ŠìŒ)
        ]

        # --- ì¡°í–¥ê° ìŠ¤ë¬´ë”© íŒŒë¼ë¯¸í„° ---
        self.last_steering_deg = 0.0
        self.angle_buffer = deque(maxlen=3)

        self.lane_center_x = None
        self.lane_center_y = None
        self.lane_angle_rad = None
        
        # --- ë³´ìƒ í•¨ìˆ˜ ê°€ì¤‘ì¹˜ ---
        self.W_STABILITY = 1.0
        self.W_SPEED = 0.2
        
        # --- ì •ì  ì‹œìŠ¤í…œ íŒŒë¼ë¯¸í„° ---
        self.image_center_x = 320
        self.pixel_to_meter = 1.9 / 650.0
        self.deg_to_servo_scale = 5.0 / 3.0
        self.deg_to_servo_offset = 2.0
        self.max_delta_angle = 7.0

        # --- ì‹¤ì‹œê°„ ìƒíƒœ ë³€ìˆ˜ ---
        self.current_cte = 0.0
        self.current_heading_error = 0.0
        
        # --- RL ê²½í—˜(Transition) êµ¬ì„± ìš”ì†Œ ---
        self.last_state = None
        self.last_action = None
        
        # --- ì—í”¼ì†Œë“œ íë¦„ ì œì–´ í”Œë˜ê·¸ ---
        self.episode_done = True
        self.goal_reached = False
        self.goal_shutdown_imminent = False
        self.reset_requested = False
        self.emergency_stop_activated = False

        # --- í•™ìŠµ í†µê³„ ê¸°ë¡ ---
        self.episode_count = 0
        self.step_count = 0
        self.current_episode_score = 0
        self.scores_window = deque(maxlen=100)
        
        # --- ROS2 í†µì‹  ì¸í„°í˜ì´ìŠ¤ ---
        self.lane_sub = self.create_subscription(Point, '/lane_point', self.lane_callback, 1)
        self.motor_pub = self.create_publisher(Float32MultiArray, '/xycar_motor', 10)
        self.checker_sub = self.create_subscription(Bool, '/checkerboard_detect', self.checkerboard_callback, 10)
        
        # --- ë¹„ë™ê¸° í‚¤ë³´ë“œ ì…ë ¥ ì²˜ë¦¬ ---
        self.key_listener_thread = threading.Thread(target=self._keyboard_listener)
        self.key_listener_thread.daemon = True
        self.key_listener_thread.start()

        # --- ë…¸ë“œ ì‹œì‘ ì•ˆë‚´ ë©”ì‹œì§€ (ì´ì „ê³¼ ë™ì¼) ---
        log_info = "Stanley Controller - TEST MODE" if test_mode else "ğŸ¯ Stanley RL Trainer Node Ready"
        self.get_logger().info("==============================================")
        self.get_logger().info(f"<<<<< {log_info} >>>>>")
        self.get_logger().info("   Press 'r' to start/reset an episode.")
        self.get_logger().info("   Press 'f' for EMERGENCY STOP.")
        self.get_logger().info("==============================================")

    def _keyboard_listener(self):
        if not sys.stdin.isatty():
            self.get_logger().warn("í‚¤ë³´ë“œ ì…ë ¥ì„ ìœ„í•œ í„°ë¯¸ë„(TTY)ì´ ì—†ìŠµë‹ˆë‹¤. í‚¤ë³´ë“œ ì œì–´ê°€ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
            return
        old_settings = termios.tcgetattr(sys.stdin)
        try:
            tty.setcbreak(sys.stdin.fileno())
            while rclpy.ok():
                char = sys.stdin.read(1)
                if char == 'r': self.reset_requested = True
                elif char == 'f': self.emergency_stop_activated = True
        except termios.error: pass
        finally: termios.tcsetattr(sys.stdin, termios.TCSADRAIN, old_settings)

    def checkerboard_callback(self, msg: Bool):
        if msg.data and not self.goal_reached:
            self.goal_reached = True
            self.get_logger().info("ğŸ Goal (Checkerboard) Detected! Preparing to stop.")

    def _get_state(self) -> np.ndarray:
        """
        í™˜ê²½ì˜ ì—¬ëŸ¬ ë³€ìˆ˜ë“¤ì„ ì¡°í•©í•˜ì—¬, ì—ì´ì „íŠ¸ê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœì˜
        í•˜ë‚˜ì˜ 'ìƒíƒœ(State)' ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        """
        ### ë³€ê²½ì  3: ì¤‘ì•™ ê´€ë¦¬ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒíƒœ êµ¬ì„± ###
        state = [
            self.current_cte,
            self.current_heading_error,
            self.last_steering_deg,
            self.control_params['speed'],
            self.control_params['k'],
            self.control_params['heading_weight']
        ]
        return np.array(state, dtype=np.float32)

    def _calculate_reward(self) -> float:
        """
        ì—ì´ì „íŠ¸ì˜ í–‰ë™ ê²°ê³¼ê°€ ì–¼ë§ˆë‚˜ ì¢‹ì•˜ëŠ”ì§€ë¥¼ ì •ëŸ‰ì ì¸ 'ë³´ìƒ(Reward)' ê°’ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.
        """
        stability_reward_norm = np.tanh(1.0 / (abs(self.current_cte) + 0.1))
        ### ë³€ê²½ì  4: ì¤‘ì•™ ê´€ë¦¬ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë³´ìƒ ê³„ì‚° ###
        speed_reward_norm = self.control_params['speed'] / 20.0 # ìµœëŒ€ ì†ë„ ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™”
        reward = self.W_STABILITY * stability_reward_norm + self.W_SPEED * speed_reward_norm
        return reward
    
    def reset(self) -> np.ndarray:
        """
        í•˜ë‚˜ì˜ ì—í”¼ì†Œë“œë¥¼ ëë‚´ê³ , ë‹¤ìŒ ì—í”¼ì†Œë“œë¥¼ ìœ„í•´ ëª¨ë“  ê´€ë ¨ ë³€ìˆ˜ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        """
        ### ë³€ê²½ì  5: ì¤‘ì•™ ê´€ë¦¬ íŒŒë¼ë¯¸í„° ì´ˆê¸°í™” ###
        self.control_params = {'k': 1.0, 'speed': 10.0, 'heading_weight': 0.4}
        
        self.last_steering_deg, self.current_cte, self.current_heading_error = 0.0, 0.0, 0.0
        self.last_state, self.last_action = None, None
        
        self.episode_done, self.goal_reached, self.goal_shutdown_imminent = False, False, False
        self.reset_requested, self.emergency_stop_activated = False, False

        if not self.is_test_mode:
            self.episode_count += 1
            self.current_episode_score = 0
            self.step_count = 0
            self.get_logger().info(f"--- Episode {self.episode_count} Started ---")
        else:
            self.get_logger().info("--- Test Episode Started ---")

        return self._get_state()
    
    @staticmethod
    def compute_steering_angle_stanley(lane_center_x, lane_center_y, lane_angle_rad,
                                       image_center_x, pixel_to_meter, heading_weight, 
                                       deg_to_servo_scale, deg_to_servo_offset, k):
        cte_pixel = lane_center_x - image_center_x
        cte = cte_pixel * pixel_to_meter
        heading_error = lane_angle_rad
        
        cte_term = np.arctan2(k * cte, 3.0) # ì†ë„ í•­ì€ ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ ìƒìˆ˜ë¡œ ê°€ì • (í˜¹ì€ speed íŒŒë¼ë¯¸í„° ì‚¬ìš© ê°€ëŠ¥)
        steering_angle_rad = heading_weight * heading_error + cte_term
        
        steering_angle_deg = np.degrees(steering_angle_rad)
        servo_angle = steering_angle_deg * deg_to_servo_scale + deg_to_servo_offset
        return servo_angle, heading_error, cte
    
    # ì¡°í–¥ê° ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (ì´ì „ê³¼ ë™ì¼)
    @staticmethod
    def clamp_angle(angle): return max(min(angle, 100.0), -100.0)
    def limit_angle_change(self, current, last): return last + max(-self.max_delta_angle, min(current - last, self.max_delta_angle))
    def smooth_angle(self, new_angle):
        self.angle_buffer.append(new_angle)
        return sum(self.angle_buffer) / len(self.angle_buffer)

    ### ë³€ê²½ì  6: `_update_param` í—¬í¼ í•¨ìˆ˜ ì¶”ê°€ ###
    def _update_param(self, params, key, delta):
        """í–‰ë™ì— ë”°ë¼ ì œì–´ íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸í•˜ê³  ë²”ìœ„ë¥¼ ì œí•œí•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
        params[key] += delta
        if key == 'k':
            params[key] = np.clip(params[key], 0.1, 3.0)
        elif key == 'heading_weight':
            params[key] = np.clip(params[key], 0.0, 1.0)
        elif key == 'speed':
            params[key] = np.clip(params[key], 5, 20)
        return params

    def _execute_action(self, action: int):
        """
        ì—ì´ì „íŠ¸ê°€ ì„ íƒí•œ í–‰ë™ì— ë”°ë¼ ì œì–´ íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸í•˜ê³ ,
        ìƒˆ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ Stanley ì œì–´ ì¡°í–¥ê°ì„ ê³„ì‚° ë° ë°œí–‰í•©ë‹ˆë‹¤.
        """
        ### ë³€ê²½ì  7: `action_map`ì„ ì´ìš©í•œ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ ###
        # action_mapì—ì„œ í•´ë‹¹ actionì— ë§ëŠ” ì—…ë°ì´íŠ¸ í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
        self.control_params = self.action_map[action](self.control_params)

        # ì—…ë°ì´íŠ¸ëœ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ Stanley ì œì–´ê¸°ë²•ìœ¼ë¡œ ì¡°í–¥ê° ê³„ì‚°
        servo_angle, _, _ = self.compute_steering_angle_stanley(
            lane_center_x=self.lane_center_x,
            lane_center_y=self.lane_center_y,
            lane_angle_rad=self.lane_angle_rad,
            image_center_x=self.image_center_x,
            pixel_to_meter=self.pixel_to_meter,
            deg_to_servo_scale=self.deg_to_servo_scale,
            deg_to_servo_offset=self.deg_to_servo_offset,
            # ì¤‘ì•™ ê´€ë¦¬ë˜ëŠ” íŒŒë¼ë¯¸í„° ì‚¬ìš©
            k=self.control_params['k'],
            heading_weight=self.control_params['heading_weight']
        )
        
        # ì¡°í–¥ê° ìŠ¤ë¬´ë”© ë° ì œí•œ (ì´ì „ê³¼ ë™ì¼í•œ ë¡œì§)
        limited_angle = self.limit_angle_change(servo_angle, self.last_steering_deg)
        smoothed_angle = self.smooth_angle(limited_angle)
        final_angle = self.clamp_angle(smoothed_angle)
        
        # ëª¨í„° ëª…ë ¹ ë°œí–‰
        motor_msg = Float32MultiArray()
        motor_msg.data = [final_angle, self.control_params['speed']]
        self.motor_pub.publish(motor_msg)
        
        self.last_steering_deg = final_angle

    def _execute_stop_command(self):
        motor_msg = Float32MultiArray()
        motor_msg.data = [0.0, 0.0]
        self.motor_pub.publish(motor_msg)

    def lane_callback(self, msg: Point):
        """
        ì„¼ì„œ ë°ì´í„°ê°€ ìˆ˜ì‹ ë  ë•Œë§ˆë‹¤ í˜¸ì¶œë˜ëŠ” ë©”ì¸ ë£¨í”„(Main Loop)ì…ë‹ˆë‹¤.
        RLì˜ (State -> Action -> Reward -> next_State) ì‚¬ì´í´ì´ ì—¬ê¸°ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤.
        """
        self.lane_center_x = msg.x
        self.lane_center_y = msg.y
        self.lane_angle_rad = msg.z
        
        # ë¹„ìƒ ì •ì§€ ë˜ëŠ” ìˆ˜ë™ ë¦¬ì…‹ ì²˜ë¦¬ (ì´ì „ê³¼ ë™ì¼)
        if self.emergency_stop_activated or self.reset_requested:
            is_manual_reset = self.reset_requested
            self._execute_stop_command()
            if not self.episode_done and not self.is_test_mode:
                reason = "MANUAL RESET" if is_manual_reset else "EMERGENCY STOP"
                self.get_logger().info(f"--- Episode Finished by {reason} ---")
                self.agent.save_model()
            
            self.episode_done = True
            if is_manual_reset: self.reset()
            return
            
        if self.episode_done: return
            
        # í˜„ì¬ ìƒíƒœ ì˜¤ì°¨ ê³„ì‚°
        self.current_cte = (msg.x - self.image_center_x) * self.pixel_to_meter
        self.current_heading_error = msg.z
        
        # í…ŒìŠ¤íŠ¸ ëª¨ë“œ ë¡œì§ (ì´ì „ê³¼ ê±°ì˜ ë™ì¼)
        if self.is_test_mode:
            state = self._get_state()
            action = self.agent.select_action(state, eval_mode=True).item()
            self._execute_action(action)
            self.get_logger().info(f"CTE: {self.current_cte:.3f}, Speed: {self.control_params['speed']:.1f}, Action: {action}", throttle_duration_sec=0.2)
            # ... (ì´í•˜ ìƒëµ)
            return

        # --- í•™ìŠµ ëª¨ë“œ ë©”ì¸ ë¡œì§ ---
        self.step_count += 1
        device = next(self.agent.policy_net.parameters()).device
        
        current_state = self._get_state()
        
        if self.last_state is not None:
            reward = self._calculate_reward()
            self.current_episode_score += reward
            self.agent.memory.push(self.last_state, self.last_action, current_state, torch.tensor([reward], device=device))
        
        is_off_track = abs(self.current_cte) > 1.0
        done = is_off_track or self.goal_shutdown_imminent

        if done:
            self.episode_done = True
            final_reward = 200.0 if self.goal_reached else -100.0
            self.current_episode_score += final_reward
            if self.last_state is not None:
                self.agent.memory.push(current_state, self.last_action, None, torch.tensor([final_reward], device=device))

            self.scores_window.append(self.current_episode_score)
            avg_score = np.mean(self.scores_window)
            result_msg = 'Success!' if self.goal_reached else 'Off Track'
            self.get_logger().info(
                f"--- Episode {self.episode_count} Finished ---\n"
                f"Score: {self.current_episode_score:.2f}, Avg Score: {avg_score:.2f}\n"
                f"Result: {result_msg}"
            )
            if not self.is_test_mode: self.agent.save_model()
            return

        if self.goal_reached and not self.goal_shutdown_imminent:
            self._execute_stop_command()
            self.goal_shutdown_imminent = True
            action_tensor = torch.tensor([[self.action_dim - 1]], device=device, dtype=torch.long) # No-op
        else:
            action_tensor = self.agent.select_action(current_state, eval_mode=False)
            self._execute_action(action_tensor.item())

        self.last_state = current_state
        self.last_action = action_tensor
        
        self.agent.optimize_model()
        self.agent.update_target_net()

        if self.agent.steps_done % 20 == 0:
            eps = self.agent.EPS_END + (self.agent.EPS_START - self.agent.EPS_END) * \
                  math.exp(-1. * self.agent.steps_done / self.agent.EPS_DECAY)
            
            ### ë³€ê²½ì  8: ë¡œê·¸ ë©”ì‹œì§€ì—ì„œ ì¤‘ì•™ ê´€ë¦¬ íŒŒë¼ë¯¸í„° ì‚¬ìš© ###
            log_msg = (
                f"[Ep.{self.episode_count:03d} | Step.{self.step_count:04d}] "
                f"CTE: {self.current_cte:+.3f} | "
                f"Action: {action_tensor.item()} | "
                f"Eps: {eps:.3f} | "
                f"Params(k/speed/h_w): {self.control_params['k']:.2f}/{self.control_params['speed']:.1f}/{self.control_params['heading_weight']:.2f}"
            )
            self.get_logger().info(log_msg)


def main(args=None):
    rclpy.init(args=args)
    node = None
    try:
        # ë¦¬íŒ©í† ë§ëœ í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        node = StanleyEnv(test_mode=False) 
        rclpy.spin(node)
    except KeyboardInterrupt:
        if node: node.get_logger().info("Training stopped by user (Ctrl+C).")
    except termios.error: pass
    finally:
        if node:
            if not node.is_test_mode:
                node.get_logger().info("Saving model on shutdown...")
                node.agent.save_model()
            node.destroy_node()
            rclpy.shutdown()

if __name__ == '__main__':
    main()