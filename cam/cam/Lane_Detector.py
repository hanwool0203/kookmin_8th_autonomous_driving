#! /usr/bin/env python
# -*- coding:utf-8 -*-
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from geometry_msgs.msg import Point
from cv_bridge import CvBridge
from std_msgs.msg import String
import cv2
import numpy as np
from collections import deque

# ===============================
# 13pixels = 2.5cm (ì°¨ì„  í­)
# 82.5cm (ì¢Œìš°ì°¨ì„  ì¤‘ì•™ì„ ëì ìœ¼ë¡œ)
# 41.25cm = 214.5pixels
# ===============================

# =============================================================================
# ì˜¤ë¥¸ìª½ ì°¨ì„ (ì¤‘ì•™ + ì˜¤ë¥¸ìª½ ì¤‘ê°„)ìœ¼ë¡œ ì£¼í–‰
# ros2 topic pub --once /lane_override_cmd std_msgs/String "data: 'go_right'"

# ì™¼ìª½ ì°¨ì„ (ì™¼ìª½ + ì¤‘ì•™ ì¤‘ê°„)ìœ¼ë¡œ ì£¼í–‰
# ros2 topic pub --once /lane_override_cmd std_msgs/String "data: 'go_left'"

# ë‹¤ì‹œ ì¤‘ì•™ì°¨ì„ ìœ¼ë¡œ ë³µê·€
# ros2 topic pub --once /lane_override_cmd std_msgs/String "data: 'reset'"
# =============================================================================

clicked_points = []

### ===== ë§ˆìš°ìŠ¤ í´ë¦­ìœ¼ë¡œ ë‘ ì ì„ ì„ íƒí•´ xì¶• ê±°ë¦¬(px)ë¥¼ ê³„ì‚°í•˜ê³  ì´ë¯¸ì§€ì— í‘œì‹œí•œë‹¤ =====
def click_and_measure(event, x, y, flags, param):
    global clicked_points
    if event == cv2.EVENT_LBUTTONDOWN:
        clicked_points.append((x, y))
        print(f'Point {len(clicked_points)}: ({x}, {y})')
        if len(clicked_points) == 2:
            pt1, pt2 = clicked_points
            dist = abs(pt1[0] - pt2[0])
            print(f'X-distance between points: {dist:.2f} pixels')
            marked_img = param.copy()
            cv2.line(marked_img, pt1, pt2, (255, 255, 0), 2)
            mid_pt = ((pt1[0]+pt2[0])//2, (pt1[1]+pt2[1])//2)
            cv2.putText(marked_img, f"X distance{dist:.1f}px", mid_pt, cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,255), 2)
            cv2.imshow("marked", marked_img)
            clicked_points = []

class Lane_Detector(Node):

    def __init__(self):
        super().__init__('lane_detector')

        self.img_sub = self.create_subscription(Image, '/image_raw', self.image_callback, 10)
        self.trigger_sub = self.create_subscription(String,'/lane_override_cmd', self.trigger_callback, 10)
        self.lane_point_pub = self.create_publisher(Point, '/lane_point', 10)

        # ğŸ”§ ì¶”ê°€: ìƒíƒœ/ì´ë²¤íŠ¸ í¼ë¸”ë¦¬ì…”
        self.mode_pub  = self.create_publisher(String, '/lane_mode', 10)
        self.current_mode = 'center'   # 'center' | 'left' | 'right'

        self.bridge = CvBridge()
        self.get_logger().info('ğŸ›£ï¸  Lane_Detector Node Started Successfullyâ—')

        # 0. ì´ˆê¸°ê°’
        self.angle = 0.0
        self.lane = np.array([120.0, 320.0, 520.0])  # ì´ˆê¸° ì™¼ìª½, ì¤‘ì•™, ì˜¤ë¥¸ìª½ ì°¨ì„ ì˜ xì¢Œí‘œ

        # 2. apply_canny
        self.canny_low = 50
        self.canny_high = 150

        # 3. detect_lines_hough 
        self.hough_threshold = 25
        self.min_gap = 1
        self.min_length = 10

        # 4. filter_lines_by_angle
        self.angle_tolerance = np.radians(30)       # y=60pxì—ì„œ í˜„ì¬ ì°¨ì„  ë°©í–¥ê³¼ì˜ í—ˆìš© ê°ë„ ì°¨ì´ (degree)
        self.prev_angle = deque([0.0], maxlen=3)    # (6 ì—ì„œë„ ì‚¬ìš©ë¨)

        # 5. extract_lane_candidates_from_clusters
        self.cluster_threshold = 30                 # ìœ„ì¹˜ê°’ë“¤ì„ í´ëŸ¬ìŠ¤í„°ë¡œ ë¬¶ì„ ë•Œ, í‰ê· ê°’ê³¼ì˜ ìµœëŒ€ í—ˆìš© ê±°ë¦¬(ì„ê³„ê°’)

        # 6. predict_lane
        self.left_offset = -200
        self.right_offset = 200
        self.angle_correction_gain = 80             # ì˜ˆì¸¡ ì°¨ì„  ìœ„ì¹˜ ë³´ì • ì‹œ ê°ë„ ë³€í™”ëŸ‰ì— ê³±í•´ì§ˆ ë³´ì • ê³„ìˆ˜ 
        self.min_cos_angle = 0.5                    # (7 ì—ì„œë„ ì‚¬ìš©ë¨) ì°¨ì„  ê°ë„ê°€ ë„ˆë¬´ ê¸°ìš¸ì–´ì§ˆ ê²½ìš°ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•œ ìµœì†Œ cos(ê°ë„) ê°’
        self.angle_prev_weight = 0.7                # ì´ì „ ê°ë„ì— ëŒ€í•œ ê°€ì¤‘ì¹˜
        self.angle_new_weight  = 0.3                # í˜„ì¬ í”„ë ˆì„ ê°ë„ì— ëŒ€í•œ ê°€ì¤‘ì¹˜

        # 7. refine_lane_with_candidates_and_prediction
        self.left_to_center_dist = 200
        self.right_to_center_dist = 200
        self.outer_lane_dist = self.left_to_center_dist + self.right_to_center_dist
        self.cluster_match_threshold = 70           ### ì˜ˆìƒëœ ì°¨ì„  ìœ„ì¹˜ì™€ ì‹¤ì œ í›„ë³´ ê°„ì˜ í—ˆìš© ê±°ë¦¬
        self.lane_update_weight = 0.7               ### ìµœì¢… ì°¨ì„  ìœ„ì¹˜ ê³„ì‚° ì‹œ í˜„ì¬ ê´€ì¸¡ê°’ì— ëŒ€í•œ ë°˜ì˜ ë¹„ìœ¨
        self.prediction_weight = 0.3                ### ìµœì¢… ì°¨ì„  ìœ„ì¹˜ ê³„ì‚° ì‹œ ì˜ˆì¸¡ê°’ì— ëŒ€í•œ ë°˜ì˜ ë¹„ìœ¨
        self.max_lane_delta = 30                    # í•œ í”„ë ˆì„ì—ì„œ í—ˆìš©ë˜ëŠ” ìµœëŒ€ ì°¨ì„  ë³€í™”ëŸ‰ [í”½ì…€]

        # 8. trigger_callback
        self.override_target_lane = None            # 'go_right', 'go_left' ë“±


    ### ===== ì›ê·¼ ë³€í™˜ì„ í†µí•´ ì˜ìƒì„ íƒ‘ë‹¤ìš´ ì‹œì ì˜ Bird's Eye Viewë¡œ ë³€í™˜í•œë‹¤ =====
    def get_birds_eye_view(self, image):
        height, width = image.shape[:2]
        output_width = 640
        output_height = 120
        src = np.float32([
            [width * 0.16, height * 0.64],      # TOP-LEFT
            [width * 0.84, height * 0.64],      # TOP-RIGHT
            [width * 1.00, height * 0.72],      # BOT-RIGHT
            [width * 0.00, height * 0.72]       # BOT-LEFT
        ])
        dst = np.float32([
            [output_width * 0.1, 0],
            [output_width * 0.9, 0],
            [output_width * 0.9, output_height],
            [output_width * 0.1, output_height]
        ])
        M = cv2.getPerspectiveTransform(src, dst)
        bev = cv2.warpPerspective(image, M, (output_width, output_height))
        self.bev_img_w = output_width
        self.bev_img_h = output_height
        self.bev_img_mid = output_height // 2
        return bev, src

    ### ===== ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ í›„ ìºë‹ˆ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì´ë¯¸ì§€ì˜ ì—ì§€(ìœ¤ê³½ì„ )ë¥¼ ê²€ì¶œí•œë‹¤ =====
    def apply_canny(self, img, show=False):
        if len(img.shape) == 3:
            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        img = cv2.GaussianBlur(img, (7,7), 0)
        img = cv2.Canny(img, self.canny_low, self.canny_high)
        if show:
            cv2.imshow('canny', img)
        return img

    ### ===== í™•ë¥ ì  í—ˆí”„ ë³€í™˜ì„ ì´ìš©í•´ ì´ë¯¸ì§€ì—ì„œ ì§ì„ (ì„ ë¶„)ë“¤ì„ ê²€ì¶œí•œë‹¤ =====
    def detect_lines_hough(self, img, show=False):
        lines = cv2.HoughLinesP(img, 1, np.pi/180, self.hough_threshold, self.min_gap, self.min_length)
        if show:
            hough_img = np.zeros((img.shape[0], img.shape[1], 3))
            if lines is not None:
                for x1, y1, x2, y2 in lines[:, 0]:
                    cv2.line(hough_img, (x1, y1), (x2, y2), (0, 0, 255), 2)
            cv2.imshow('hough', hough_img)
        return lines

    ### ===== í˜„ì¬ ì°¨ì„  ê°ë„ì™€ ìœ ì‚¬í•œ ì§ì„ ë“¤ë§Œ í•„í„°ë§í•˜ì—¬ ì°¨ì„  í›„ë³´ ìœ„ì¹˜(xì¢Œí‘œ)ë¥¼ ì¶”ì¶œí•œë‹¤ =====
    def filter_lines_by_angle(self, lines, show=True):
        thetas, positions = [], []
        if show:
            filter_img = np.zeros((self.bev_img_h, self.bev_img_w, 3))
        if lines is not None:
            for x1, y1, x2, y2 in lines[:, 0]:
                if y1 == y2:
                    continue
                flag = 1 if y1-y2 > 0 else -1
                theta = np.arctan2(flag * (x2-x1), flag * (y1-y2))      # í—ˆí”„ ë³€í™˜ìœ¼ë¡œ ê²€ì¶œëœ ë‘ ëì ìœ¼ë¡œë¶€í„° ê³„ì‚°
                if abs(theta - self.angle) < self.angle_tolerance:      # í˜„ì¬ ì„ ë¶„ì˜ ë°©í–¥(theta)ê³¼ ê³¼ê±° ì°¨ì„  ë°©í–¥(self.angle)ì˜ ì°¨ì´
                    position = float((x2-x1)*(self.bev_img_mid-y1))/(y2-y1) + x1    # 60pxì—ì„œ ê° ì§ì„ ì˜ ìœ„ì¹˜ x (ë‹¨ì¼)
                    thetas.append(theta)
                    positions.append(position)                                      # 60pxì—ì„œ ê° ì§ì„ ì˜ ìœ„ì¹˜ x (ë¦¬ìŠ¤íŠ¸)
                    if show:
                        cv2.line(filter_img, (x1, y1), (x2, y2), (0, 0, 255), 2)
        self.prev_angle.append(self.angle)
        if thetas:
            new_angle = np.mean(thetas)                                 # ì´ì „ í”„ë ˆì„ì—ì„œ í•„í„°ë§ëœ ëª¨ë“  ì„ ì˜ ê°ë„ ë¦¬ìŠ¤íŠ¸ thetaì˜ í‰ê· 
            self.angle = self.angle_prev_weight * self.angle + self.angle_new_weight * new_angle
        if show:
            cv2.imshow('filtered lines by angle', filter_img)
        return positions

    ### ===== ìœ„ì¹˜ê°’ë“¤ì„ í´ëŸ¬ìŠ¤í„°ë§í•˜ì—¬ í‰ê· ê°’ ê¸°ì¤€ì˜ ì°¨ì„  í›„ë³´ ì¢Œí‘œë“¤ì„ ì¶”ì¶œí•œë‹¤ =====
    def extract_lane_candidates_from_clusters(self, positions, show=False, base_img=None):
        clusters = []                               # ì—¬ëŸ¬ ê°œì˜ clusterë¥¼ ë‹´ì€ ì „ì²´ ë¦¬ìŠ¤íŠ¸ (2ì°¨ì› ë¦¬ìŠ¤íŠ¸)
        for position in positions:
            if 0 <= position < self.bev_img_w:
                for cluster in clusters:            # ìœ ì‚¬í•œ xì¢Œí‘œë“¤ì„ ëª¨ì€ í•˜ë‚˜ì˜ ê·¸ë£¹ (1ì°¨ì› ë¦¬ìŠ¤íŠ¸)
                    cluster_mean = np.mean(cluster)
                    if abs(cluster_mean - position) < self.cluster_threshold:
                        cluster.append(position)
                        break
                else:
                    clusters.append([position])
        lane_candidates = [np.mean(cluster) for cluster in clusters]

        if show and base_img is not None:
            cluster_img = cv2.cvtColor(base_img.copy(), cv2.COLOR_GRAY2BGR)
            np.random.seed(42)
            colors = [tuple(map(int, np.random.randint(0, 255, size=3))) for _ in range(len(clusters))]
            for idx, cluster in enumerate(clusters):
                color = colors[idx]
                for x in cluster:
                    cv2.circle(cluster_img, (int(x), self.bev_img_mid), 4, color, -1)
            cv2.imshow('Clustered Lane Positions', cluster_img)
        return lane_candidates

    ### ===== ì´ì „ ì°¨ì„  ìœ„ì¹˜ì™€ ê°ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í˜„ì¬ í”„ë ˆì„ì˜ ì°¨ì„  ìœ„ì¹˜ë¥¼ ì˜ˆì¸¡í•œë‹¤ =====
    def predict_lane(self, show=False, base_img=None):
        denom = max(np.cos(self.angle), self.min_cos_angle)
        predicted_lane = self.lane[1] + np.array([
            self.left_offset / denom,
            0,
            self.right_offset / denom
        ])
        predicted_lane += (self.angle - np.mean(self.prev_angle)) * self.angle_correction_gain

        if show and base_img is not None:
            img = cv2.cvtColor(base_img.copy(), cv2.COLOR_GRAY2BGR) if len(base_img.shape) == 2 else base_img.copy()
            y = self.bev_img_mid
            cv2.circle(img, (int(predicted_lane[0]), y), 4, (255, 0, 255), 2)       # ì¢Œì¸¡ ì˜ˆì¸¡ (ë³´ë¼)
            cv2.circle(img, (int(predicted_lane[1]), y), 4, (128, 128, 128), 2)     # ì¤‘ì•™ ì˜ˆì¸¡ (íšŒìƒ‰)
            cv2.circle(img, (int(predicted_lane[2]), y), 4, (255, 255, 0), 2)       # ìš°ì¸¡ ì˜ˆì¸¡ (ë…¸ë‘)
            cv2.putText(img, 'Pred_L', (int(predicted_lane[0]) - 20, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 255), 1)
            cv2.putText(img, 'Pred_C', (int(predicted_lane[1]) - 20, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (128, 128, 128), 1)
            cv2.putText(img, 'Pred_R', (int(predicted_lane[2]) - 20, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)
            cv2.imshow('Predicted Lane', img)
        return predicted_lane
        
    ### ===== ì˜ˆì¸¡ëœ ì°¨ì„ ê³¼ í›„ë³´ ì°¨ì„ ì„ ë¹„êµí•˜ì—¬ ê°€ì¥ ìœ ì‚¬í•œ ì¡°í•©ì„ ì„ íƒí•˜ê³  ìµœì¢… ì°¨ì„  ìœ„ì¹˜ë¥¼ ë³´ì •í•œë‹¤ =====
    def refine_lane_with_candidates_and_prediction(self, lane_candidates, predicted_lane):
        if not lane_candidates:
            self.lane = predicted_lane
            return
        possibles = []
        cos_angle = max(np.cos(self.angle), self.min_cos_angle)
        for lc in lane_candidates:
            idx = np.argmin(abs(self.lane - lc))
            if idx == 0:
                estimated_lane = [
                    lc,
                    lc + self.left_to_center_dist / cos_angle,
                    lc + self.outer_lane_dist / cos_angle
                ]
                lc2_candidate = [c for c in lane_candidates if abs(c - estimated_lane[1]) < self.cluster_match_threshold]
                lc3_candidate = [c for c in lane_candidates if abs(c - estimated_lane[2]) < self.cluster_match_threshold]
                if not lc2_candidate:
                    lc2_candidate.append(estimated_lane[1])
                if not lc3_candidate:
                    lc3_candidate.append(estimated_lane[2])
                for lc2 in lc2_candidate:
                    for lc3 in lc3_candidate:
                        possibles.append([lc, lc2, lc3])
            elif idx == 1:
                estimated_lane = [
                    lc - self.left_to_center_dist / cos_angle,
                    lc,
                    lc + self.right_to_center_dist / cos_angle
                ]
                lc1_candidate = [c for c in lane_candidates if abs(c - estimated_lane[0]) < self.cluster_match_threshold]
                lc3_candidate = [c for c in lane_candidates if abs(c - estimated_lane[2]) < self.cluster_match_threshold]
                if not lc1_candidate:
                    lc1_candidate.append(estimated_lane[0])
                if not lc3_candidate:
                    lc3_candidate.append(estimated_lane[2])
                for lc1 in lc1_candidate:
                    for lc3 in lc3_candidate:
                        possibles.append([lc1, lc, lc3])
            else:
                estimated_lane = [
                    lc - self.outer_lane_dist / cos_angle,
                    lc - self.right_to_center_dist / cos_angle,
                    lc
                ]
                lc1_candidate = [c for c in lane_candidates if abs(c - estimated_lane[0]) < self.cluster_match_threshold]
                lc2_candidate = [c for c in lane_candidates if abs(c - estimated_lane[1]) < self.cluster_match_threshold]
                if not lc1_candidate:
                    lc1_candidate.append(estimated_lane[0])
                if not lc2_candidate:
                    lc2_candidate.append(estimated_lane[1])
                for lc1 in lc1_candidate:
                    for lc2 in lc2_candidate:
                        possibles.append([lc1, lc2, lc])
        
        possibles = np.array(possibles)
        error = np.sum((possibles - predicted_lane) ** 2, axis=1)
        best = possibles[np.argmin(error)]
        new_lane = self.lane_update_weight * best + self.prediction_weight * predicted_lane

        delta = new_lane - self.lane
        delta_clipped = np.clip(delta, -self.max_lane_delta, self.max_lane_delta)
        self.lane = self.lane + delta_clipped

    ### ===== ìµœì¢… ê²°ì •ëœ ì°¨ì„  ì¢Œí‘œë“¤ê³¼ ê·¸ ì¤‘ì•™ê°’ë“¤ì„ ì´ë¯¸ì§€ì— ì‹œê°í™”í•˜ì—¬ í‘œì‹œí•œë‹¤ =====
    def mark_lane(self, img, lane=None, show=False):
        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
        if lane is None:
            lane = self.lane
        l1, l2, l3 = lane
        cv2.circle(img, (int(l1), self.bev_img_mid), 3, (255, 0, 0), 5, cv2.FILLED)     # BLUE
        cv2.circle(img, (int(l2), self.bev_img_mid), 3, (0, 255, 255), 5, cv2.FILLED)   # YELLOW
        cv2.circle(img, (int(l3), self.bev_img_mid), 3, (0, 0, 255), 5, cv2.FILLED)     # RED

        mid_left = (l1 + l2) / 2
        mid_right = (l2 + l3) / 2
        cv2.circle(img, (int(mid_left), self.bev_img_mid), 4, (0, 255, 0), 4, cv2.FILLED)   # GREEN
        cv2.putText(img, 'go_L', (int(mid_left)-20, self.bev_img_mid - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1)
        cv2.circle(img, (int(mid_right), self.bev_img_mid), 4, (0, 255, 0), 4, cv2.FILLED)  # GREEN
        cv2.putText(img, 'go_R', (int(mid_right)-20, self.bev_img_mid - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1)

        if show:
            cv2.imshow('marked_lane_point', img)
            cv2.setMouseCallback('marked_lane_point', click_and_measure, img.copy())

    ### ===== ì›ë³¸ ì´ë¯¸ì§€ì— BEV ë³€í™˜ ì˜ì—­ì„ í´ë¦¬ë¼ì¸ìœ¼ë¡œ í‘œì‹œí•˜ì—¬ ì‹œê°í™”í•œë‹¤ =====
    def show_roi_region(self, img, src, show=False):
        if show:
            COLOR = (0,255,0)
            THICKNESS = 2
            cv2.polylines(img, [src.astype(int)], True, COLOR, THICKNESS, cv2.LINE_AA)
            cv2.imshow('roi region on the undistorted frame',img)
        else :
            pass

    ### ===== ìˆ˜ì‹ ëœ ì´ë¯¸ì§€ì—ì„œ ì°¨ì„ ì„ ì¸ì‹í•˜ê³ , ìµœì¢… ì¤‘ì•™ ì°¨ì„  ìœ„ì¹˜ì™€ ê°ë„ë¥¼ ê³„ì‚°í•˜ì—¬ í¼ë¸”ë¦¬ì‹œí•œë‹¤ =====
    def image_callback(self, msg):
        frame = self.bridge.imgmsg_to_cv2(msg, 'bgr8')
        canny = self.apply_canny(frame, show=False)
        bev, src = self.get_birds_eye_view(canny)
        self.show_roi_region(frame, src, show=True)
        lines = self.detect_lines_hough(bev, show=False)
        positions = self.filter_lines_by_angle(lines, show=False)
        lane_candidates = self.extract_lane_candidates_from_clusters(positions,show=False,base_img=bev)

        predicted_lane = self.predict_lane(show=False, base_img=bev)
        self.refine_lane_with_candidates_and_prediction(lane_candidates, predicted_lane)
        self.mark_lane(bev, show=True)

        lane_msg = Point()

        if self.override_target_lane == 'go_right':
            mode_str = 'right'
            lane_msg.x = (self.lane[1] + self.lane[2]) / 2
        elif self.override_target_lane == 'go_left':
            mode_str = 'left'
            lane_msg.x = (self.lane[0] + self.lane[1]) / 2
        else:
            mode_str = 'center'
            lane_msg.x = self.lane[1]

        lane_msg.y = float(self.bev_img_mid)
        lane_msg.z = self.angle

        self.lane_point_pub.publish(lane_msg)
        self.mode_pub.publish(String(data=mode_str))

        # í˜„ì¬ ëª¨ë“œê°€ override ëª…ë ¹ê³¼ ë‹¤ë¥¼ ê²½ìš°ì—ë§Œ ë°œí–‰í•˜ì—¬ ë¶ˆí•„ìš”í•œ ë©”ì‹œì§€ ì¤„ì„
        if mode_str != self.current_mode:
            self.current_mode = mode_str
            self.mode_pub.publish(String(data=self.current_mode))

        cv2.waitKey(1)
        

    ### ===== ì™¸ë¶€ ëª…ë ¹(go_right/go_left)ì— ë”°ë¼ ì°¨ì„  ì„ íƒì„ ê°•ì œë¡œ ì§€ì •í•˜ê±°ë‚˜ ì´ˆê¸°í™”í•œë‹¤ =====
    def trigger_callback(self, msg):  # std_msgs/String
        command = msg.data.strip().lower()

        # 1) override_target_lane ë¨¼ì € ê°±ì‹ 
        if command == 'go_right':
            self.override_target_lane = 'go_right'
        elif command == 'go_left':
            self.override_target_lane = 'go_left'
        elif command == 'reset':
            self.override_target_lane = None
        else:
            self.get_logger().warn(f'âš ï¸ [Command Received] unknown: {command}')
            return

        # if self.override_target_lane == 'go_right':
        #     new_mode = 'right'
        # elif self.override_target_lane == 'go_left':
        #     new_mode = 'left'
        # else:
        #     new_mode = 'center'

        # if new_mode != self.current_mode:
        #     self.current_mode = new_mode


        
    
def main(args=None):
    rclpy.init(args=args)
    node = Lane_Detector()
    rclpy.spin(node)
    node.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()
